{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9530d1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a86167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "\n",
    "import os.path\n",
    "\n",
    "datasetdir = os.path.join('.', 'dataset')\n",
    "filename = 'games.csv'\n",
    "path = os.path.join(datasetdir, filename)\n",
    "\n",
    "data = pd.read_csv(path, index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3af0107",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmed = data['rating'].median()\n",
    "armed = data['aggregated_rating'].median()\n",
    "for idx in data.index:\n",
    "    if np.isnan(data.loc[idx, 'rating']) and np.isnan(data.loc[idx, 'aggregated_rating']):\n",
    "        data.loc[idx, 'rating'] = rmed\n",
    "        data.loc[idx, 'aggregated_rating'] = armed\n",
    "    elif np.isnan(data.loc[idx, 'rating']):\n",
    "        data.loc[idx, 'rating'] = data.loc[idx, 'aggregated_rating']\n",
    "    elif np.isnan(data.loc[idx, 'aggregated_rating']):\n",
    "        data.loc[idx, 'aggregated_rating'] = data.loc[idx, 'rating']\n",
    "    else:\n",
    "        data.loc[idx, 'rating'] = rmed\n",
    "        data.loc[idx, 'aggregated_rating'] = armed\n",
    "        \n",
    "\n",
    "data['rating_count'].fillna(value=0, inplace=True)\n",
    "data['follows'].fillna(value=0, inplace=True)\n",
    "data['game_modes'].fillna(value='1', inplace=True)\n",
    "\n",
    "\n",
    "data['keywords'].fillna(value='', inplace=True)\n",
    "data['summary'].fillna(value='', inplace=True)\n",
    "data['storyline'].fillna(value='', inplace=True)\n",
    "for idx in data.index:\n",
    "    if (data.loc[idx, 'summary'] != '') and (data.loc[idx, 'storyline'] != ''):\n",
    "        data.loc[idx, 'storyline'] = data.loc[idx, 'storyline'] + ' ' + data.loc[idx, 'summary']\n",
    "    if (data.loc[idx, 'summary'] != '') and (data.loc[idx, 'storyline'] == ''):\n",
    "        data.loc[idx, 'storyline'] = data.loc[idx, 'summary']\n",
    "\n",
    "\n",
    "data['year'] = pd.to_datetime(data['first_release_date'], unit='s').dt.year\n",
    "data['player_perspectives'].fillna(value='7', inplace=True)\n",
    "\n",
    "data['campaigncoop'].fillna(value=False, inplace=True)\n",
    "data['dropin'].fillna(value=False, inplace=True)\n",
    "data['lancoop'].fillna(value=False, inplace=True)\n",
    "data['offlinecoop'].fillna(value=False, inplace=True)\n",
    "data['onlinecoop'].fillna(value=False, inplace=True)\n",
    "data['splitscreen'].fillna(value=False, inplace=True)\n",
    "\n",
    "data.drop(['category', 'multiplayer_modes', 'similar_games', 'offlinecoopmax', 'rating_count', 'summary', \n",
    "           'offlinemax',  'onlinecoopmax', 'onlinemax', 'platform', 'first_release_date', 'involved_companies'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a177e998",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tony\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Tony\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Tony\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Tony\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a463527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemmatizer(text):\n",
    "    wl = WordNetLemmatizer()\n",
    "    def get_wordnet_pos(tag):\n",
    "        if tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "\n",
    "    lemmatized_sentence = []\n",
    "    tokenizer = RegexpTokenizer(r'\\w+[-]?\\w+')\n",
    "    words = tokenizer.tokenize(text)\n",
    "    word_pos_tags = nltk.pos_tag(words)\n",
    "\n",
    "    for idx, tag in enumerate(word_pos_tags):\n",
    "        lemmatized_sentence.append(wl.lemmatize(tag[0], get_wordnet_pos(tag[1])))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2d9980",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['keywords'] = data['keywords'].apply(lambda x: x if x == '' else lemmatizer(x).lower())\n",
    "data['storyline'] = data['storyline'].apply(lambda x: x if x == '' else lemmatizer(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79a3a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stopwords\n",
    "stopw = stopwords.ENGLISH_STOP_WORDS\n",
    "\n",
    "keywords_dict = dict()\n",
    "for s in data['keywords'].dropna().values:\n",
    "    for w in s.split():\n",
    "        if w in keywords_dict:\n",
    "            keywords_dict[w] += 1\n",
    "        else:\n",
    "            keywords_dict[w] = 1\n",
    "\n",
    "keywords_dict = {k: keywords_dict[k] for k in keywords_dict if (keywords_dict[k] > 30) and (k not in stopw)}\n",
    "keywords_set = set(keywords_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7adfb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in data.index:\n",
    "    if data.loc[idx, 'keywords'] == '':\n",
    "        keywords = []\n",
    "        for k in data.loc[idx, 'storyline'].split():\n",
    "            if k in keywords_set:\n",
    "                keywords.append(k)\n",
    "        data.loc[idx, 'keywords'] = ' '.join(keywords)\n",
    "    if data.loc[idx, 'storyline'] == '':\n",
    "        data.loc[idx, 'storyline'] = str(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4865698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63848, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
      "C:\\Users\\Tony\\AppData\\Local\\Temp\\ipykernel_3648\\846883515.py:24: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = y_buf.astype(np.int).values\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy\n",
    "from random import choices\n",
    "\n",
    "X, y = data[~pd.isna(data['themes'])][['keywords', 'storyline']], data[~pd.isna(data['themes'])]['themes']\n",
    "\n",
    "y = [[int(j) for j in i.split()] for i in y]\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "print(y.shape)\n",
    "labels = [i[0] for i in sorted(enumerate(y.sum(axis=0)), key=lambda x: x[1] )] # indexes of class samples in descending order of quantity\n",
    "y = pd.DataFrame(y, index=X.index)\n",
    "y_buf = pd.DataFrame(columns=y.columns)\n",
    "\n",
    "\n",
    "for l in labels:\n",
    "    k = 15000 - int(y_buf.sum()[l])\n",
    "    if k > 0:\n",
    "        y_buf = y_buf.append(y.loc[choices( list(y[y[l] == 1].index), k=k) ] )\n",
    "\n",
    "y = y_buf.astype(np.int).values       \n",
    "X = X.loc[y_buf.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e66ff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_key = CountVectorizer(stop_words=stopw)\n",
    "vectorizer_story = CountVectorizer(stop_words=stopw)\n",
    "X_key = vectorizer_key.fit_transform(X['keywords'])\n",
    "X_story = vectorizer_story.fit_transform(X['storyline'])\n",
    "X = scipy.sparse.hstack((X_key, X_story))\n",
    "\n",
    "clf = OneVsRestClassifier(XGBClassifier(n_jobs=-1, max_depth=5,  n_estimators=100))\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3099389",
   "metadata": {},
   "outputs": [],
   "source": [
    "emptythemes = pd.isna(data['themes'])\n",
    "X_key = vectorizer_key.transform(data[emptythemes]['keywords'])\n",
    "X_story = vectorizer_story.transform(data[emptythemes]['storyline'])\n",
    "X = scipy.sparse.hstack((X_key, X_story))\n",
    "predictionthemes = mlb.inverse_transform(clf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021973c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, value in zip(emptythemes.index, predictionthemes):\n",
    "    data.loc[idx, 'themes'] = ' '.join([str(i) for i in value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionthemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da306028",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['themes'].fillna(value='', inplace=True)\n",
    "themes = {'thriller': '20',\n",
    "          'sci-fi': '18',\n",
    "          'action': '1',\n",
    "          'horror': '19',\n",
    "          'survival': '21',\n",
    "          'fantasy': '17',\n",
    "          'historical': '22',\n",
    "          'stealth': '23',\n",
    "          'comedy': '27',\n",
    "          'business': '28',\n",
    "          'drama': '31',\n",
    "          'non-fiction': '32',\n",
    "          'kids': '35',\n",
    "          'sandbox': '33',\n",
    "          'open world': '38',\n",
    "          'warfare': '39',\n",
    "          '4x': '41',\n",
    "          'educational': '34',\n",
    "          'mystery': '43',\n",
    "          'party': '40',\n",
    "          'romance': '44',\n",
    "          'erotic': '42'}\n",
    "\n",
    "data['genres'].fillna(value='', inplace=True)\n",
    "genres = {'fighting': '4',\n",
    "          'shooter': '5',\n",
    "          'music': '7',\n",
    "          'platform': '8',\n",
    "          'puzzle': '9',\n",
    "          'racing': '10',\n",
    "          'real time strategy': '11',\n",
    "          'rts': '11',\n",
    "          'role-playing': '12',\n",
    "          'rpg': '12',\n",
    "          'simulator': '13',\n",
    "          'sport': '14',\n",
    "          'strategy': '15',\n",
    "          'turn-based strategy': '16',\n",
    "          'turn based strategy': '16',\n",
    "          'tbs': '16',\n",
    "          'tactical': '24',\n",
    "          'quiz': '26',\n",
    "          'trivia': '26',\n",
    "          'hack and slash': '25',\n",
    "          'hack slash': '25',\n",
    "          'beat em up': '25',\n",
    "          'pinball': '30',\n",
    "          'adventure': '31',\n",
    "          'arcade': '33',\n",
    "          'visual novel': '34',\n",
    "          'indie': '32',\n",
    "          'card game': '35',\n",
    "          'board game': '35',\n",
    "          'moba': '36',\n",
    "          'point and click': '2',\n",
    "          'point click': '2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43acb080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "datasetdir = os.path.join('.', 'dataset')\n",
    "filename = 'games.clean.csv'\n",
    "path = os.path.join(datasetdir, filename)\n",
    "data.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcgames = data[data['platforms'].apply(str.split).apply(lambda x: [int(i) for i in x]).apply(lambda x: 6 in x)]\n",
    "pcgames.loc[[pcgames[(pcgames['year'] == i)]['follows'].idxmax() for i in range(1990, 2023)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acdfdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['themes'][100:140]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
